VisionEncoderDecoderModel(

  (encoder): TimesformerModel(

    (embeddings): TimesformerEmbeddings(
      (patch_embeddings): TimesformerPatchEmbeddings(
        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (time_drop): Dropout(p=0.0, inplace=False)

    )
    (encoder): TimesformerEncoder(
      (layer): ModuleList(

        (0-11): 12 x TimesformerLayer(
          (drop_path): Identity()
          (attention): TimeSformerAttention(
            (attention): TimesformerSelfAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (output): TimesformerSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): TimesformerIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (intermediate_act_fn): GELUActivation()
          )
          (output): TimesformerOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (temporal_attention): TimeSformerAttention(
            (attention): TimesformerSelfAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (output): TimesformerSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (temporal_dense): Linear(in_features=768, out_features=768, bias=True)
        )
      )
    )
    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): GPT2LMHeadModel(
    (transformer): GPT2Model(
      (wte): Embedding(50257, 768)
      (wpe): Embedding(1024, 768)
      (drop): Dropout(p=0.1, inplace=False)
      (h): ModuleList(
        (0-11): 12 x GPT2Block(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): GPT2Attention(
            (c_attn): Conv1D(nf=2304, nx=768)
            (c_proj): Conv1D(nf=768, nx=768)
            (attn_dropout): Dropout(p=0.1, inplace=False)
            (resid_dropout): Dropout(p=0.1, inplace=False)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (crossattention): GPT2Attention(
            (c_attn): Conv1D(nf=1536, nx=768)
            (q_attn): Conv1D(nf=768, nx=768)
            (c_proj): Conv1D(nf=768, nx=768)
            (attn_dropout): Dropout(p=0.1, inplace=False)
            (resid_dropout): Dropout(p=0.1, inplace=False)
          )
          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): GPT2MLP(
            (c_fc): Conv1D(nf=3072, nx=768)
            (c_proj): Conv1D(nf=768, nx=3072)
            (act): NewGELUActivation()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): Linear(in_features=768, out_features=50257, bias=False)
  )
)


=====================================================================================================================================================================
Layer (type:depth-idx)                                            Input Shape               Output Shape              Param #                   Trainable
=====================================================================================================================================================================
VisionEncoderDecoderModel                                         [1, 8, 3, 224, 224]       [1, 1569, 768]            --                        True
├─TimesformerModel: 1-1                                           --                        [1, 1569, 768]            --                        True
│    └─T  └─TimesformerPatchEmbeddings: 3-1                       [1, 8, 3, 224, 224]       [8, 196, 768]             --                        True
│    │    │    └─Conv2d: 4-1                                      [8, 3, 224, 224]          [8, 768, 14, 14]          590,592                   True
│    │    └─Dropout: 3-2                                          [8, 197, 768]             [8, 197, 768]             --                        --
│    │    └─Dropout: 3-3                                          [196, 8, 768]             [196, 8, 768]             --                        --
│    └─TimesformerEncoder: 2-2                                    [1, 1569, 768]            [1, 1569, 768]            --                        True
│    │    └─ModuleList: 3-4                                       --                        --                        --                        True
│    │    │    └─TimesformerLayer: 4-2                            [1, 1569, 768]            [1, 1569, 768]            10,042,368                True
│    │    │    └─TimesformerLayer: 4-3                            [1, 1569, 768]            [1, 1569, 768]            10,042,368                True
│    │    │    └─TimesformerLayer: 4-4                            [1, 1569, 768]            [1, 1569, 768]            10,042,368                True
│    │    │    └─TimesformerLayer: 4-5                            [1, 1569, 768]            [1, 1569, 768]            10,042,368                True
│    │    │    └─TimesformerLayer: 4-6                            [1, 1569, 768]            [1, 1569, 768]            10,042,368                True
│    │    │    └─TimesformerLayer: 4-7                            [1, 1569, 768]            [1, 1569, 768]            10,042,368                True
│    │    │    └─TimesformerLayer: 4-8                            [1, 1569, 768]            [1, 1569, 768]            10,042,368                True
│    │    │    └─TimesformerLayer: 4-9                            [1, 1569, 768]            [1, 1569, 768]            10,042,368                True
│    │    │    └─TimesformerLayer: 4-10                           [1, 1569, 768]            [1, 1569, 768]            10,042,368                True
│    │    │    └─TimesformerLayer: 4-11                           [1, 1569, 768]            [1, 1569, 768]            10,042,368                True
│    │    │    └─TimesformerLayer: 4-12                           [1, 1569, 768]            [1, 1569, 768]            10,042,368                True
│    │    │    └─TimesformerLayer: 4-13                           [1, 1569, 768]            [1, 1569, 768]            10,042,368                True
│    └─LayerNorm: 2-3                                             [1, 1569, 768]            [1, 1569, 768]            1,536                     True
├─GPT2LMHeadModel: 1-2                                            --                        [1, 12, 1024, 64]         --                        True
│    └─GPT2Model: 2-4                                             [1, 1024]                 [1, 12, 1024, 64]         --                        True
│    │    └─Embedding: 3-5                                        [1, 1024]                 [1, 1024, 768]            38,597,376                True
│    │    └─Embedding: 3-6                                        [1, 1024]                 [1, 1024, 768]            786,432                   True
│    │    └─Dropout: 3-7                                          [1, 1024, 768]            [1, 1024, 768]            --                        --
│    │    └─ModuleList: 3-8                                       --                        --                        --                        True
│    │    │    └─GPT2Block: 4-14          imesformerEmbeddings: 2-1                                 [1, 8, 3, 224, 224]       [1, 1569, 768]            158,208                   True
│    │                          [1, 1024, 768]            [1, 1024, 768]            9,451,776                 True
│    │    │    └─GPT2Block: 4-15                                  [1, 1024, 768]            [1, 1024, 768]            9,451,776                 True
│    │    │    └─GPT2Block: 4-16                                  [1, 1024, 768]            [1, 1024, 768]            9,451,776                 True
│    │    │    └─GPT2Block: 4-17                                  [1, 1024, 768]            [1, 1024, 768]            9,451,776                 True
│    │    │    └─GPT2Block: 4-18                                  [1, 1024, 768]            [1, 1024, 768]            9,451,776                 True
│    │    │    └─GPT2Block: 4-19                                  [1, 1024, 768]            [1, 1024, 768]            9,451,776                 True
│    │    │    └─GPT2Block: 4-20                                  [1, 1024, 768]            [1, 1024, 768]            9,451,776                 True
│    │    │    └─GPT2Block: 4-21                                  [1, 1024, 768]            [1, 1024, 768]            9,451,776                 True
│    │    │    └─GPT2Block: 4-22                                  [1, 1024, 768]            [1, 1024, 768]            9,451,776                 True
│    │    │    └─GPT2Block: 4-23                                  [1, 1024, 768]            [1, 1024, 768]            9,451,776                 True
│    │    │    └─GPT2Block: 4-24                                  [1, 1024, 768]            [1, 1024, 768]            9,451,776                 True
│    │    │    └─GPT2Block: 4-25                                  [1, 1024, 768]            [1, 1024, 768]            9,451,776                 True
│    │    └─LayerNorm: 3-9                                        [1, 1024, 768]            [1, 1024, 768]            1,536                     True
│    └─Linear: 2-5                                                [1, 1024, 768]            [1, 1024, 50257]          38,597,376                True
=====================================================================================================================================================================
Total params: 312,662,784
Trainable params: 312,662,784
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 202.78
=====================================================================================================================================================================
Input size (MB): 4.83
Forward/backward pass size (MB): 3706.86
Params size (MB): 1250.02
Estimated Total Size (MB): 4961.71
=====================================================================================================================================================================